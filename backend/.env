# --- Configuration ---
DATA_PATH="data"
PERSIST_DIRECTORY="chroma_db_persist"
EMBEDDING_MODEL_NAME="embed_models/sentence_transformer_model" # Using BGE-Base for efficiency
CHUNK_SIZE=500
CHUNK_OVERLAP=50
# --- Ollama / LLM ---
# OLLAMA_BASE_URL="http://host.docker.internal:11434" # For Docker Compose communication FROM API service TO Ollama on host
OLLAMA_BASE_URL="http://localhost:11434" # Use this if running main.py directly on host
OLLAMA_MODEL="llama3.1" # Make sure this model is pulled in Ollama
LLM_TEMPERATURE=0.7
# --- API ---
API_HOST="0.0.0.0"
API_PORT=8765
# HF_TOKEN="" # Optional Hugging Face token for private models